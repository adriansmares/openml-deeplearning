{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nDataset upload tutorial\n=======================\n\nA tutorial on how to create and upload a dataset to OpenML.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nimport sklearn.datasets\nfrom scipy.sparse import coo_matrix\n\nimport openml\nfrom openml.datasets.functions import create_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-danger\"><h4>Warning</h4><p>This example uploads data. For that reason, this example\n  connects to the test server at test.openml.org. This prevents the main\n  server from crowding with example datasets, tasks, runs, and so on.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "openml.config.start_using_configuration_for_example()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we will cover the following cases of the dataset object:\n\n* A numpy array\n* A list\n* A pandas dataframe\n* A sparse matrix\n* A pandas sparse dataframe\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset is a numpy array\n========================\nA numpy array can contain lists in the case of dense data or it can contain\nOrderedDicts in the case of sparse data.\n\nPrepare dataset\n^^^^^^^^^^^^^^^\nLoad an example dataset from scikit-learn which we will upload to OpenML.org\nvia the API.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "diabetes = sklearn.datasets.load_diabetes()\nname = 'Diabetes(scikit-learn)'\nX = diabetes.data\ny = diabetes.target\nattribute_names = diabetes.feature_names\ndescription = diabetes.DESCR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OpenML does not distinguish between the attributes and targets on the data\nlevel and stores all data in a single matrix.\n\nThe target feature is indicated as meta-data of the dataset (and tasks on\nthat data).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = np.concatenate((X, y.reshape((-1, 1))), axis=1)\nattribute_names = list(attribute_names)\nattributes = [\n    (attribute_name, 'REAL') for attribute_name in attribute_names\n] + [('class', 'INTEGER')]\ncitation = (\n    \"Bradley Efron, Trevor Hastie, Iain Johnstone and \"\n    \"Robert Tibshirani (2004) (Least Angle Regression) \"\n    \"Annals of Statistics (with discussion), 407-499\"\n)\npaper_url = (\n    'http://web.stanford.edu/~hastie/Papers/'\n    'LARS/LeastAngle_2002.pdf'\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the dataset object\n^^^^^^^^^^^^^^^^^^^^^^^^^\nThe definition of all fields can be found in the XSD files describing the\nexpected format:\n\nhttps://github.com/openml/OpenML/blob/master/openml_OS/views/pages/api_new/v1/xsd/openml.data.upload.xsd\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "diabetes_dataset = create_dataset(\n    # The name of the dataset (needs to be unique).\n    # Must not be longer than 128 characters and only contain\n    # a-z, A-Z, 0-9 and the following special characters: _\\-\\.(),\n    name=name,\n    # Textual description of the dataset.\n    description=description,\n    # The person who created the dataset.\n    creator=\"Bradley Efron, Trevor Hastie, \"\n            \"Iain Johnstone and Robert Tibshirani\",\n    # People who contributed to the current version of the dataset.\n    contributor=None,\n    # The date the data was originally collected, given by the uploader.\n    collection_date='09-01-2012',\n    # Language in which the data is represented.\n    # Starts with 1 upper case letter, rest lower case, e.g. 'English'.\n    language='English',\n    # License under which the data is/will be distributed.\n    licence='BSD (from scikit-learn)',\n    # Name of the target. Can also have multiple values (comma-separated).\n    default_target_attribute='class',\n    # The attribute that represents the row-id column, if present in the\n    # dataset.\n    row_id_attribute=None,\n    # Attributes that should be excluded in modelling, such as identifiers and\n    # indexes.\n    ignore_attribute=None,\n    # How to cite the paper.\n    citation=citation,\n    # Attributes of the data\n    attributes=attributes,\n    data=data,\n    # A version label which is provided by the user.\n    version_label='test',\n    original_data_url=(\n        'http://www4.stat.ncsu.edu/~boos/var.select/diabetes.html'\n    ),\n    paper_url=paper_url,\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "upload_did = diabetes_dataset.publish()\nprint('URL for dataset: %s/data/%d' % (openml.config.server, upload_did))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset is a list\n=================\nA list can contain lists in the case of dense data or it can contain\nOrderedDicts in the case of sparse data.\n\nWeather dataset:\nhttp://storm.cis.fordham.edu/~gweiss/data-mining/datasets.html\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = [\n    ['sunny', 85, 85, 'FALSE', 'no'],\n    ['sunny', 80, 90, 'TRUE', 'no'],\n    ['overcast', 83, 86, 'FALSE', 'yes'],\n    ['rainy', 70, 96, 'FALSE', 'yes'],\n    ['rainy', 68, 80, 'FALSE', 'yes'],\n    ['rainy', 65, 70, 'TRUE', 'no'],\n    ['overcast', 64, 65, 'TRUE', 'yes'],\n    ['sunny', 72, 95, 'FALSE', 'no'],\n    ['sunny', 69, 70, 'FALSE', 'yes'],\n    ['rainy', 75, 80, 'FALSE', 'yes'],\n    ['sunny', 75, 70, 'TRUE', 'yes'],\n    ['overcast', 72, 90, 'TRUE', 'yes'],\n    ['overcast', 81, 75, 'FALSE', 'yes'],\n    ['rainy', 71, 91, 'TRUE', 'no'],\n]\n\nattribute_names = [\n    ('outlook', ['sunny', 'overcast', 'rainy']),\n    ('temperature', 'REAL'),\n    ('humidity', 'REAL'),\n    ('windy', ['TRUE', 'FALSE']),\n    ('play', ['yes', 'no']),\n]\n\ndescription = (\n    'The weather problem is a tiny dataset that we will use repeatedly'\n    ' to illustrate machine learning methods. Entirely fictitious, it '\n    'supposedly concerns the conditions that are suitable for playing '\n    'some unspecified game. In general, instances in a dataset are '\n    'characterized by the values of features, or attributes, that measure '\n    'different aspects of the instance. In this case there are four '\n    'attributes: outlook, temperature, humidity, and windy. '\n    'The outcome is whether to play or not.'\n)\n\ncitation = (\n    'I. H. Witten, E. Frank, M. A. Hall, and ITPro,'\n    'Data mining practical machine learning tools and techniques, '\n    'third edition. Burlington, Mass.: Morgan Kaufmann Publishers, 2011'\n)\n\nweather_dataset = create_dataset(\n    name=\"Weather\",\n    description=description,\n    creator='I. H. Witten, E. Frank, M. A. Hall, and ITPro',\n    contributor=None,\n    collection_date='01-01-2011',\n    language='English',\n    licence=None,\n    default_target_attribute='play',\n    row_id_attribute=None,\n    ignore_attribute=None,\n    citation=citation,\n    attributes=attribute_names,\n    data=data,\n    version_label='example',\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "upload_did = weather_dataset.publish()\nprint('URL for dataset: %s/data/%d' % (openml.config.server, upload_did))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset is a pandas DataFrame\n=============================\nIt might happen that your dataset is made of heterogeneous data which can be\nusually stored as a Pandas DataFrame. DataFrame offers the adavantages to\nstore the type of data for each column as well as the attribute names.\nTherefore, when providing a Pandas DataFrame, OpenML can infer those\ninformation without the need to specifically provide them when calling the\nfunction :func:`create_dataset`. In this regard, you only need to pass\n``'auto'`` to the ``attributes`` parameter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data, columns=[col_name for col_name, _ in attribute_names])\n# enforce the categorical column to have a categorical dtype\ndf['outlook'] = df['outlook'].astype('category')\ndf['windy'] = df['windy'].astype('bool')\ndf['play'] = df['play'].astype('category')\nprint(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We enforce the column 'outlook', 'windy', and 'play' to be a categorical\ndtype while the column 'rnd_str' is kept as a string column. Then, we can\ncall :func:`create_dataset` by passing the dataframe and fixing the parameter\n``attributes`` to ``'auto'``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "weather_dataset = create_dataset(\n    name=\"Weather\",\n    description=description,\n    creator='I. H. Witten, E. Frank, M. A. Hall, and ITPro',\n    contributor=None,\n    collection_date='01-01-2011',\n    language='English',\n    licence=None,\n    default_target_attribute='play',\n    row_id_attribute=None,\n    ignore_attribute=None,\n    citation=citation,\n    attributes='auto',\n    data=df,\n    version_label='example',\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "upload_did = weather_dataset.publish()\nprint('URL for dataset: %s/data/%d' % (openml.config.server, upload_did))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset is a sparse matrix\n==========================\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sparse_data = coo_matrix((\n    [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n    ([0, 1, 1, 2, 2, 3, 3], [0, 1, 2, 0, 2, 0, 1])\n))\n\ncolumn_names = [\n    ('input1', 'REAL'),\n    ('input2', 'REAL'),\n    ('y', 'REAL'),\n]\n\nxor_dataset = create_dataset(\n    name=\"XOR\",\n    description='Dataset representing the XOR operation',\n    creator=None,\n    contributor=None,\n    collection_date=None,\n    language='English',\n    licence=None,\n    default_target_attribute='y',\n    row_id_attribute=None,\n    ignore_attribute=None,\n    citation=None,\n    attributes=column_names,\n    data=sparse_data,\n    version_label='example',\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "upload_did = xor_dataset.publish()\nprint('URL for dataset: %s/data/%d' % (openml.config.server, upload_did))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset is a pandas sparse dataframe\n====================================\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sparse_data = coo_matrix((\n    [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0],\n    ([0, 1, 1, 2, 2, 3, 3], [0, 1, 2, 0, 2, 0, 1])\n))\ncolumn_names = ['input1', 'input2', 'y']\ndf = pd.SparseDataFrame(sparse_data, columns=column_names)\nprint(df.info())\n\nxor_dataset = create_dataset(\n    name=\"XOR\",\n    description='Dataset representing the XOR operation',\n    creator=None,\n    contributor=None,\n    collection_date=None,\n    language='English',\n    licence=None,\n    default_target_attribute='y',\n    row_id_attribute=None,\n    ignore_attribute=None,\n    citation=None,\n    attributes='auto',\n    data=df,\n    version_label='example',\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "upload_did = xor_dataset.publish()\nprint('URL for dataset: %s/data/%d' % (openml.config.server, upload_did))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "openml.config.stop_using_configuration_for_example()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}